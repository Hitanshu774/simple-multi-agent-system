{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9cf314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY: 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\n",
      "Starts with sk-or-: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "print(\"KEY:\", key)\n",
    "print(\"Starts with sk-or-:\", key.startswith(\"sk-or-\") if key else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response: **Business Area to Explore:** **Enterprise Knowledge‑Centred Decision‑Support (e.g., legal, compliance, and risk advisory for large corporations)**  \n",
      "\n",
      "---\n",
      "\n",
      "### Why This Area is a Sweet Spot for an **Agentic AI + RAG** System\n",
      "\n",
      "| Dimension | Value Proposition |\n",
      "|-----------|-------------------|\n",
      "| **Complex, High‑Stakes Knowledge** | Large enterprises generate massive volumes of internal policies, case law, regulatory filings, audit reports, and proprietary research. Decision‑makers need *accurate, up‑to‑date* answers anchored in that corpus to mitigate legal risk, satisfy audits, or advise on compliance. |\n",
      "| **Dynamic, Multi‑Step Reasoning** | A single query often leads to a chain of dependent steps: e.g., “What GDPR‑related obligations arise when we launch a new SaaS product in the EU?” → Identify relevant regulation → Locate recent rulings → Map internal policy → Draft compliance checklist → Simulate regulator‑style Q&A. Agentic AI can orchestrate these steps autonomously, while RAG supplies the exact source passages needed at each stage. |\n",
      "| **Actionable Outputs** | Beyond answering, the system can **execute** downstream actions: generate a compliance checklist, fill a regulatory filing template, trigger a workflow in a GRC (governance‑risk‑compliance) platform, or schedule a review with a specialist. Agentic capabilities turn the RAG engine into a **self‑directed workflow engine**. |\n",
      "| **Scalability & Consistency** | Human subject‑matter experts (SMEs) are scarce and expensive. An agentic‑RAG solution can **scale** advice across units and geographies, ensuring the same rigor and traceability for every query. |\n",
      "| **Feedback Loop for Continuous Improvement** | Agents can log unanswered or disputed queries, automatically route them for fine‑tuning, and iteratively improve the retrieval index or prompt logic—creating a virtuous maintenance loop. |\n",
      "| **Regulatory & Trust ROI** | Auditable logs, provenance‑linked citations, and deterministic reasoning paths address the “black‑box” concerns typical of generative AI, making the solution palatable for legal and compliance teams. |\n",
      "\n",
      "---\n",
      "\n",
      "### A Sample End‑to‑End Use‑Case\n",
      "\n",
      "1. **User Query**: “Based on our latest supplier contract language, what IP indemnity risks do we have in the new EU data‑localisation law?”  \n",
      "2. **Planning Agent**:  \n",
      "   - Recognises three required sub‑tasks: (a) retrieve relevant contract clauses, (b) locate current EU data‑localisation statutes, (c) map the intersection to internal risk‑policy.  \n",
      "3. **RAG Retrieval Phase (per sub‑task)**:  \n",
      "   - **Clause Retrieval**: Scrape internal contract repository → surface clauses on “Intellectual Property”, “Indemnification”.  \n",
      "   - **Statutory Retrieval**: Query curated external regulatory corpus (EUR‑Lex, EU Official Gazette) → fetch latest data‑localisation amendments.  \n",
      "   - **Policy Mapping**: Search internal compliance manual for risk‑evaluation procedures.  \n",
      "4. **Synthesis Agent**:  \n",
      "   - Cross‑references retrieved passages, extracts normative language, and builds a risk narrative.  \n",
      "5. **Action Generation**:  \n",
      "   - Auto‑populate a risk‑assessment worksheet in the GRC system, suggest remediation steps (e.g., add specific data‑localisation carve‑outs), and generate a one‑page briefing for senior counsel.  \n",
      "6. **Human‑in‑the‑Loop Confirmation**:  \n",
      "   - The agent flags the output for optional review by a senior lawyer, attaching citation links to the original documents.  \n",
      "7. **Feedback Capture**:  \n",
      "   - If the lawyer edits the briefing, that edit is logged and fed back to the retrieval index (e.g., augmenting search terms) and to the prompt library (e.g., adjust phrasing of risk‑scoring rules).  \n",
      "\n",
      "---\n",
      "\n",
      "### Core Technical Building Blocks\n",
      "\n",
      "| Component | Role | Typical Implementation |\n",
      "|-----------|------|--------------------------|\n",
      "| **Retrieval Engine** | Provides *grounded* context at each planning step. | Vector DB (e.g., Pinecone, Elastic KNN) of clause embeddings + keyword filters; multi‑hop retrieval (e.g., ColBERT, RAG‑Fusion). |\n",
      "| **Planner Agent** | Breaks a high‑level question into atomic sub‑tasks, decides order, may invoke external tools (APIs, search, execution modules). | LLM‑driven planner (e.g., GPT‑4‑Turbo, Claude‑3‑Opus) with a structured “task‑graph” output; optionally use a “chain‑of‑thought” prompt to reason about dependencies. |\n",
      "| **Executive / Action Agent** | Takes retrieved snippets and performs **generation + execution** (drafts, fills forms, triggers workflows). | Structured‑output fine‑tuned model that can output JSON/YAML templates or call APIs (e.g., ServiceNow ticket creation). |\n",
      "| **Memory / State Tracker** | Keeps context across the multi‑step workflow (e.g., “the clause we are currently evaluating”). | Short‑term context window + persistent “workflow memory” store (SQLite, DynamoDB). |\n",
      "| **Verification / Trust Layer** | Serves citations, provenance metadata, and confidence scores. | Retrieval‑augmented confidence scoring; alignment with source ranking; optional “chain‑of‑evidence” visualisation. |\n",
      "| **Feedback Loop Engine** | Captures corrections, stores for index/table updates, and triggers periodic retraining/fine‑tuning. | Active‑learning pipeline where human edits are fed back to vector DB re‑indexing and prompt‑engine tuning. |\n",
      "\n",
      "---\n",
      "\n",
      "### Business Advantages & ROI Manifestations\n",
      "\n",
      "| Benefit | Quantifiable Impact |\n",
      "|---------|---------------------|\n",
      "| **Reduced Legal Overhead** | 30‑50 % reduction in attorney hours spent on routine compliance checks (estimated $2‑5 M annual savings for a mid‑size multinational). |\n",
      "| **Faster Time‑to‑Market** | Accelerate product launch approvals by 1‑2 weeks via automated risk‑review pipelines. |\n",
      "| **Risk Mitigation** | Near‑real‑time alerts on regulatory changes that could affect contracts, reducing breach exposure by up to 40 %. |\n",
      "| **Consistency & Governance** | Every recommendation is traceable to source documents; audit trails satisfy SOX/ISO 27001 requirements. |\n",
      "| **Scalable Knowledge Capture** | New contracts, policies, or regulations can be onboarded by simply ingesting them into the vector store—no re‑engineering needed. |\n",
      "| **Competitive Differentiation** | Offer clients a *self‑service* “compliance‑assistant” portal that delivers legally vetted advice instantly, opening a subscription revenue stream for the advisory platform. |\n",
      "\n",
      "---\n",
      "\n",
      "### Implementation Roadmap (High‑Level)\n",
      "\n",
      "| Phase | Duration | Key Milestones |\n",
      "|-------|----------|----------------|\n",
      "| **0 – Discovery** | 1–2 mo | Catalog internal knowledge sources (contracts, policy docs, regulatory archives). Identify pilot use‑cases (e.g., GDPR compliance checks). |\n",
      "| **1 – Prototype Retrieval & Prompting** | 2–3 mo | Build vector DB, test retrieval quality with sample legal queries; fine‑tune a retrieval‑augmented generator for citation style. |\n",
      "| **2 – Agent Planner MVP** | 3–4 mo | Implement a lightweight planner that can decompose a query into 2‑3 steps; integrate with retrieval and basic text generation. |\n",
      "| **3 – Action & Workflow Integration** | 2–3 mo | Connect planner‑generation to internal GRC APIs (e.g., ServiceNow, Airtable checklist creator). Enable audit‑trail logging. |\n",
      "| **4 – Human‑in‑the‑Loop UAT** | 2 mo | Deploy within a single legal ops team. Collect edits, confidence scores, and run active‑learning loops. |\n",
      "| **5 – Scale & Govern** | Ongoing | Expand to additional jurisdictions and compliance domains; embed continuous model monitoring; define SOPs for governance and version control. |\n",
      "\n",
      "---\n",
      "\n",
      "### Competitive Landscape Snapshot\n",
      "\n",
      "| Competitor/Solution | Core Offering | Gap that Our Agentic‑RAG System Fills |\n",
      "|---------------------|---------------|--------------------------------------|\n",
      "| **Traditional Document Search + RAG Chatbots** | Static Q&A, often single‑turn. | *Multi‑step planning, autonomous tool use, and workflow execution*. |\n",
      "| **Rule‑Engine Based Compliance Platforms** | Hard‑coded logic, brittle when regulations change. | *Adaptive reasoning that can adapt to new language, integrate new sources without re‑coding*. |\n",
      "| **LLM‑Only Advisory Tools** | Full‑sentence generative answers, but lack grounding. | *RAG guarantees citation provenance, reduces hallucination, ensures alignment with internal policies*. |\n",
      "| **Human‑Only Advisory** | Expert coverage but cost‑prohibitive at scale. | *Human‑in‑the‑loop augmentation that scales expertise and cuts cost*. |\n",
      "\n",
      "---\n",
      "\n",
      "## TL;DR Takeaway\n",
      "\n",
      "**Enterprise Knowledge‑Centred Decision‑Support (Legal & Compliance)** is a high‑value business area where an **Agentic AI system built on Retrieval‑Augmented Generation** can:\n",
      "\n",
      "* Deliver *grounded, quasi‑expert* advice without dependence on scarce SME bandwidth.  \n",
      "* Orchestrate **multi‑hop reasoning → retrieval → synthesis → action** in a self‑directed workflow.  \n",
      "* Provide **traceability, auditability, and continuous learning**, making it acceptable to regulated industries.  \n",
      "\n",
      "By turning a static RAG pipeline into an autonomous agent that **plans, executes, verifies, and iterates**, you can unlock measurable cost savings, risk reduction, and new revenue streams for large enterprises.  \n",
      "\n",
      "---  \n",
      "\n",
      "*Ready to dive deeper?* Let me know if you’d like a more detailed architecture diagram, a sample prompt template for the planner, or a cost‑benefit model specific to a particular industry vertical.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from datetime import datetime\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "##############################################################################\n",
    "def store_agent_output(\n",
    "    prompt: str,\n",
    "    output: str,\n",
    "    model_name: str,\n",
    "    path: str = \"agent_runs.jsonl\",\n",
    "    extra_metadata: dict | None = None\n",
    "):\n",
    "    record = {\n",
    "        \"run_id\": str(uuid.uuid4()),\n",
    "        \"prompt\": prompt,\n",
    "        \"final_output\": output,\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"metadata\": extra_metadata or {}\n",
    "    }\n",
    "\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "#############################################################################3\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "# First API call with reasoning\n",
    "response = client.chat.completions.create(\n",
    "  model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
    "  messages=[\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"pick a business area that might be worth exploring for an Agentic AI combined with RAG system opportunity.\"\n",
    "          }\n",
    "        ],\n",
    "  extra_body={\"reasoning\": {\"enabled\": True}}\n",
    ")\n",
    "\n",
    "# Extract the assistant message with reasoning_details\n",
    "response = response.choices[0].message\n",
    "print(\"First response:\", response.content)\n",
    "\n",
    "########################################################################################################\n",
    "# Preserve the assistant message with reasoning_details\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": \"pick a business area that might be worth exploring for an Agentic AI combined with RAG system opportunity.\"},\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.content,\n",
    "    \"reasoning_details\": response.reasoning_details  # Pass back unmodified\n",
    "  },\n",
    "  {\"role\": \"user\", \"content\": \"Make sure it generates good amount of revenue.\"}\n",
    "]\n",
    "\n",
    "# Second API call - model continues reasoning from where it left off\n",
    "response2 = client.chat.completions.create(\n",
    "  model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
    "  messages=messages,\n",
    "  extra_body={\"reasoning\": {\"enabled\": True}}\n",
    ")\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": \"pick a business area that might be worth exploring for an Agentic AI combined with RAG system opportunity.\"},\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.content,\n",
    "    \"reasoning_details\": response.reasoning_details  # Pass back unmodified\n",
    "  },\n",
    "  {\"role\": \"user\", \"content\": \"Make sure it generates good amount of revenue.\"},\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response2.choices[0].message.content,\n",
    "    \"reasoning_details\": response2.choices[0].message.reasoning_details  # Pass back unmodified\n",
    "  },\n",
    "  {\"role\": \"user\", \"content\": \"Now propose the agentic AI solution.\"}\n",
    "]\n",
    "# Third API call - model continues reasoning from where it left off\n",
    "response3 = client.chat.completions.create(\n",
    "  model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
    "  messages=messages,\n",
    "  extra_body={\"reasoning\": {\"enabled\": True}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680a894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8a243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c37221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
